{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Mohamed-Amine Baazizi\n",
    "Affiliation: LIP6 - Faculté des Sciences - Sorbonne Université\n",
    "Email: mohamed-amine.baazizi@lip6.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interrogation de données structurées en Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but du TME est de formuler des requêtes SQL en utilisant l'API Dataframe de Spark, en Scala.\n",
    "Pour la documentation à consulter, suivre ces liens:\n",
    "* https://spark.apache.org/docs/latest/sql-programming-guide.html\n",
    "* https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TME  utilise le jeux de données Books qui renseigne sur des livres (books.csv), des utilsateurs (users.csv) et des notes réalisées par les utilsateurs (ratings.csv).\n",
    "\n",
    "Le schéma de la base est  \n",
    "\n",
    "* `Users (userid: Number, country: Text, age: Number)`\n",
    "* `Books (bookid: Number, titlewords: Number, authorwords: Number, year: Number, publisher: Number)`\n",
    "* `Ratings (userid: Number, bookid: Number, rating: Number)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappels de quelques fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Expression |Action|\n",
    "|:-------------:|:-------------:|\n",
    "|val ds = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/path/file.csv\") |loads the content of file.csv into a dataset ds by indicting that it contains a header  and by requesting  Spark to infer the schema | \n",
    "|ds.printSchema | show the schema of ds |\n",
    "|ds.show(truncate=false)|shows the first 20 rows without truncating the values |\n",
    "|ds.describe().show()|collects and shows descriptive statistics (mean, max, count, ..) of numeric values|\n",
    "|ds.select(\"c1\", \"c2\", ..., \"cn\")|projects ds on the columns c1, …, cn|\n",
    "|ds.withColumnRenamed(\"c1\",\"c2\")|renames the column c1 with c2|\n",
    "|ds.where(cond)|selects the rows respecting cond|\n",
    "|ds.groupBy(\"c1\").agg(collect_list($\"c2\") as \"values\")|groups the rows by column c1 and creates an new column of values associated to those of c1|\n",
    "|ds.groupBy(\"c1\").agg(avg(\"c2\"))|computes the sum of c2 for each c1 |\n",
    "|ds.withColumn(\"new\", Exp)|creates a new column whose values are computed by Exp|\n",
    "|ds1.crossJoin(ds2)|computes the cross product of ds1 and ds2|\n",
    "|ds1.join(ds2, \"c\") |joins ds1 and ds2 on the column c|\n",
    "|ds1.join(ds2, Seq(\"c1\",...,\"cn\")) |generalizes the previous one to a sequence of columns c1,…, cn|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path: String = C:/Users/yousef/Desktop/Books/\r\n",
       "users_df: org.apache.spark.sql.DataFrame = [userid: int, country: string ... 1 more field]\r\n",
       "books_df: org.apache.spark.sql.DataFrame = [bookid: int, titlewords: int ... 3 more fields]\r\n",
       "ratings_df: org.apache.spark.sql.DataFrame = [userid: int, bookid: int ... 1 more field]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = \"C:/Users/yousef/Desktop/Books/\"\n",
    "//\"/tmp/BDLE/dataset/Books/\" \n",
    "val users_df = spark.read.format(\"csv\").\n",
    "option(\"header\", \"true\").option(\"inferSchema\", \"true\").\n",
    "load(path +\"users.csv\")\n",
    "\n",
    "val books_df = spark.read.format(\"csv\")\n",
    ".option(\"header\", \"true\").option(\"inferSchema\", \"true\")\n",
    ".load(path +\"books.csv\")\n",
    "\n",
    "val ratings_df = spark.read.format(\"csv\")\n",
    ".option(\"header\", \"true\").option(\"inferSchema\", \"true\")\n",
    ".load(path +\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pour examiner les schemas exécutez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userid: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- bookid: integer (nullable = true)\n",
      " |-- titlewords: integer (nullable = true)\n",
      " |-- authorwords: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- publisher: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- userid: integer (nullable = true)\n",
      " |-- bookid: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()\n",
    "books_df.printSchema()\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pour extraire quelques statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+------------------+\n",
      "|summary|            userid|country|               age|\n",
      "+-------+------------------+-------+------------------+\n",
      "|  count|             27876|  27876|             27876|\n",
      "|   mean|139492.66404792652|   null| 23.93001147940881|\n",
      "| stddev| 80461.72293106595|   null|20.897392248233995|\n",
      "|    min|                 8|albania|                 0|\n",
      "|    max|            278854|    ysa|               244|\n",
      "+-------+------------------+-------+------------------+\n",
      "\n",
      "+-------+-----------------+------------------+-------------------+------------------+------------------+\n",
      "|summary|           bookid|        titlewords|        authorwords|              year|         publisher|\n",
      "+-------+-----------------+------------------+-------------------+------------------+------------------+\n",
      "|  count|            49972|             49972|              49972|             49972|             49972|\n",
      "|   mean|69322.26789001841|5.6949891939486115|  2.196490034419275|1959.3767309693428| 597.3513767709918|\n",
      "| stddev|57203.64943519578|3.9153431337188005|0.46398076292751067| 266.3549546585172|1398.3412585142266|\n",
      "|    min|                2|                 1|                  1|                 0|                 1|\n",
      "|    max|           270919|                45|                  9|              2050|             15678|\n",
      "+-------+-----------------+------------------+-------------------+------------------+------------------+\n",
      "\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|summary|            userid|           bookid|            rating|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|            253120|           253120|            253120|\n",
      "|   mean|136161.38191371682|38995.89727402023| 2.989724241466498|\n",
      "| stddev|  80808.3360639414|47648.23813574937|1.3282196125954941|\n",
      "|    min|                 8|                2|                 1|\n",
      "|    max|            278854|           270919|                 5|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.describe().show()\n",
    "books_df.describe().show()\n",
    "ratings_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formuler les requêtes retournant les infromations suivantes.\n",
    "Réponsre à chaque question en déclarant une variable portant le même nom que la question.\n",
    "Exemple: `val s0 = ….` pour la question s0.\n",
    "\n",
    "Pour visualiser les résultats d'une requête, invoquer la méthode `show()` sur la valeur associée.\n",
    "Exemple: `s0.show()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requêtes simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s0) Identifiants des utilisateurs du pays 'france'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---+\n",
      "|userid|country|age|\n",
      "+------+-------+---+\n",
      "|100681| france| 54|\n",
      "|101742| france| 26|\n",
      "|105187| france| 53|\n",
      "|106040| france| 29|\n",
      "|107767| france| 17|\n",
      "|108153| france| 53|\n",
      "|108551| france| 28|\n",
      "|109040| france| 26|\n",
      "|110367| france| 21|\n",
      "|110572| france| 18|\n",
      "|113275| france| 38|\n",
      "|114043| france| 58|\n",
      "|115198| france| 31|\n",
      "|115259| france| 32|\n",
      "|117941| france| 33|\n",
      "| 11881| france| 32|\n",
      "|118846| france| 29|\n",
      "|119859| france| 53|\n",
      "|120332| france| 41|\n",
      "|121070| france| 27|\n",
      "+------+-------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s0: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userid: int, country: string ... 1 more field]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val s0 = users_df.where(\"country=\\\"france\\\"\")\n",
    "s0.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s1) Identifiants des livres  publiés en 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+----+---------+\n",
      "|bookid|titlewords|authorwords|year|publisher|\n",
      "+------+----------+-----------+----+---------+\n",
      "|    29|         1|          2|2000|       28|\n",
      "|    37|         2|          2|2000|       32|\n",
      "|    45|         1|          3|2000|       39|\n",
      "|    52|        12|          2|2000|       42|\n",
      "|    81|         2|          2|2000|       61|\n",
      "|    84|         2|          2|2000|       64|\n",
      "|   102|        19|          3|2000|       74|\n",
      "|   114|         2|          2|2000|       74|\n",
      "|   120|         2|          2|2000|       80|\n",
      "|   127|         6|          2|2000|       40|\n",
      "|   162|         3|          2|2000|       74|\n",
      "|   170|         3|          3|2000|       26|\n",
      "|   202|         5|          2|2000|      126|\n",
      "|   212|         3|          2|2000|       75|\n",
      "|   219|         2|          2|2000|      129|\n",
      "|   231|         2|          2|2000|       57|\n",
      "|   248|         4|          2|2000|      140|\n",
      "|   283|         3|          2|2000|       83|\n",
      "|   319|         5|          2|2000|      178|\n",
      "|   328|         6|          2|2000|       40|\n",
      "+------+----------+-----------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [bookid: int, titlewords: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val s1 = books_df.where(\"year=2000\")\n",
    "s1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s2) Identifiants des livres évalués avec une note > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|userid|bookid|rating|\n",
      "+------+------+------+\n",
      "|276747|  4780|     4|\n",
      "|276747|  1837|     4|\n",
      "|276772| 33829|     5|\n",
      "|276772| 83629|     5|\n",
      "|276788| 19993|     5|\n",
      "|276814| 14817|     4|\n",
      "|276822| 17085|     5|\n",
      "|276822| 34237|     4|\n",
      "|276822|178121|     5|\n",
      "|276822|233882|     4|\n",
      "|276822|  1028|     4|\n",
      "|276822| 27517|     5|\n",
      "|276822| 88357|     4|\n",
      "|276822| 15603|     5|\n",
      "|276822| 50712|     5|\n",
      "|276822|140338|     5|\n",
      "|276847| 82884|     5|\n",
      "|276847|  8273|     5|\n",
      "|276847| 52802|     4|\n",
      "|276847|  5733|     5|\n",
      "+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userid: int, bookid: int ... 1 more field]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val s2 = ratings_df.where(\"rating>3\")\n",
    "s2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requêtes avec agrégation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q1) Nombre d'utilisateurs par pays  avec tri décroissant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       country|count|\n",
      "+--------------+-----+\n",
      "|           usa|18935|\n",
      "|        canada| 2505|\n",
      "|       germany| 1254|\n",
      "|       unknown| 1069|\n",
      "|united kingdom| 1019|\n",
      "|     australia|  581|\n",
      "|         spain|  518|\n",
      "|        france|  309|\n",
      "|         italy|  211|\n",
      "|      portugal|  184|\n",
      "|   switzerland|  176|\n",
      "|   netherlands|  147|\n",
      "|   new zealand|  113|\n",
      "|      malaysia|   99|\n",
      "|       austria|   97|\n",
      "|     singapore|   52|\n",
      "|        brazil|   39|\n",
      "|       finland|   38|\n",
      "|       ireland|   36|\n",
      "|   philippines|   32|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "q1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [country: string, count: bigint]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q1 = users_df.groupBy(\"country\").count().sort(desc(\"count\"))\n",
    "//ds.groupBy(\"c1\").agg(avg(\"c2\"))\n",
    "q1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q2) Pays qui a le plus grand nombre d'utilisateurs. Il n y a pas d'ex aequo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|country|count|\n",
      "+-------+-----+\n",
      "|    usa|18935|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "q2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [country: string, count: bigint]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q2 = q1.limit(1)\n",
    "q2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q3) Année avec le plus grand nombre de livres édités. Il n y a pas d'ex aequo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2002| 4529|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "q3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [year: int, count: bigint]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q3 = books_df.groupBy(\"year\").count().sort(desc(\"count\")).limit(1)\n",
    "q3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q4) Editeurs ayant édité plus de 10 livres en totalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|publisher|count|\n",
      "+---------+-----+\n",
      "|       28| 1261|\n",
      "|       40| 1166|\n",
      "|      149| 1066|\n",
      "|        7|  998|\n",
      "|       56|  964|\n",
      "|       39|  954|\n",
      "|       74|  885|\n",
      "|       35|  827|\n",
      "|       36|  777|\n",
      "|       57|  776|\n",
      "|       25|  633|\n",
      "|      140|  599|\n",
      "|      160|  587|\n",
      "|      213|  548|\n",
      "|       66|  524|\n",
      "|       92|  518|\n",
      "|       41|  477|\n",
      "|       53|  447|\n",
      "|      134|  425|\n",
      "|       34|  416|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "q4: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [publisher: int, count: bigint]\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q4 = books_df.groupBy(\"publisher\").count().where(\"count>10\").sort(desc(\"count\"))\n",
    "q4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q5) Editeurs ayant édité plus de 5 livres à chaque année où ils ont édité un livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q5: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [publisher: int]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q5 = books_df.\n",
    "q5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q6) La note moyenne par livre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q6: org.apache.spark.sql.DataFrame = [bookid: int, avg(rating): double]\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q6 = ratings_df.\n",
    "q6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q7) La nombre de livres ayant été eu le note 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q: Long = 47327\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q = ratings_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q8) L'identifiant de l'utilisateur ayant noté le plus grand nombre de livres. Pas d'ex eaquo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q8: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userid: int, count: bigint]\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q8 = ratings_df.\n",
    "q8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requêtes avec jointures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q9) Les éditeurs des livres notés par des utilisateurs vivant en France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q9: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [publisher: int]\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q9 = users_df.\n",
    "q9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q10) Les éditeurs des livres n'ayant pas été notés par des utilisateurs vivant en France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q10: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [publisher: int]\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q10 = books_df.\n",
    "q10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q11) Pour chaque pays, le nombre moyen de livres ayant obtenu une note >  3 attribuée par des utilisateurs de ce pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q11: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [country: string, avg: double]\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q11 = ratings_df.\n",
    "q11.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q12) Pour chaque livre, l'age moyen des utilisateurs l'ayant noté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q12: org.apache.spark.sql.DataFrame = [bookid: int, avg(age): double]\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q12 = ratings_df.\n",
    "q12.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q13) Paires d'utilisateurs ayant noté le même nombre de livres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q13a: org.apache.spark.sql.DataFrame = [userid: int, cnt_books: bigint]\n",
       "q13: org.apache.spark.sql.DataFrame = [uid: int, userid: int]\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q13 = \n",
    "\n",
    "q13.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requêtes avec  fonctions utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.UserDefinedFunction\n",
       "import scala.collection.mutable.WrappedArray\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.UserDefinedFunction\n",
    "import scala.collection.mutable.WrappedArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir deux  fonctions utilisateur `unionBooks` et `commonBooks` qui prennent en entrée deux ensembles d'identifiants de livre. \n",
    "* unionBooks retourne la cardinalité de l'union des deux ensembles de entrée\n",
    "* commonBooks retourne la cardinalité de l'intersection des deux ensembles de entrée\n",
    "\n",
    "Les ensembles en entrée sont stockés avec le type WrappedArray[Integer] de Scala déjà importé.\n",
    "\n",
    "Les résultats sont de type Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonBooks: UserDefinedFunction =  udf((l: WrappedArray[/*a completer*/], r: WrappedArray[/*a completer*/]) => /*a completer*/) \n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionBooks: UserDefinedFunction =  udf((l: WrappedArray[/*a completer*/], r: WrappedArray[/*a completer*/]) => /*a completer*/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  q14) Paires d'utilsateurs avec le nombre de livres en communn qu'ils ont notés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "24: error: not found: value rating_df\r",
     "output_type": "error",
     "traceback": [
      "<console>:24: error: not found: value rating_df\r",
      "       val q14a = rating_df.groupBy(\"userid\").agg(collect_list($\"bookid\") as \"books1\").withColumnRenamed(\"userid\",\"uid1\")\r",
      "                  ^",
      ""
     ]
    }
   ],
   "source": [
    "val q14a = rating_df.groupBy(\"userid\").agg(collect_list($\"bookid\") as \"books1\").withColumnRenamed(\"userid\",\"uid1\")\n",
    "val q14b=q14a.crossJoin(q14a.withCoulumnRenamed(\"uid1\",\"uid2\").withColumnRenamed(\"books1\",\"books2\"))\n",
    "q14b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q15) Paires d'utilsateurs avec la similarité Jaccard calculée sur les livres qu'ils ont notés.\n",
    "(Consulter https://en.wikipedia.org/wiki/Jaccard_index)\n",
    "\n",
    "Utiliser les fonctions `commonBooks` et `unionBooks`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q15: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userid_1: int, userid_2: int ... 1 more field]\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val q15 = \n",
    "q15.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### == Fin du TME == "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
