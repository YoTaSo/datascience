{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Author: Mohamed-Amine Baazizi \n",
    "* Affiliation: LIP6 - Faculté des Sciences - Sorbonne Université\n",
    "* Email: mohamed-amine.baazizi@lip6.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interrogation de données semi-structurées en Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TME illustre un exemple de bout en bout qui traite de la préparation de données de la formulation de requêtes d'analyse. \n",
    "Les données sont au format JSON qui permet de représenter les données de manière flexible avec des variations structurelles.\n",
    "\n",
    "Les traitements s'expriement dans l'API Dataset dont la documentation est accessible depuis ces deux liens :\n",
    "* https://spark.apache.org/docs/latest/sql-programming-guide.html\n",
    "* https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données utilisées correspondent à des évènements décrivant des posts échangés, partagés ou commentés sur un réseau social VK pendant l'élection présidentielle Russe. L'API officielle de ces données est décrite sur le lien https://vk.com/dev/streaming_api_docs_2?f=7.%2BЧтение%2Bпотока   \n",
    "\n",
    "Nous utiliser ces données pour analyser les posts par types, les tags utilisés dans ces post et la relation implicite entre les auteurs des posts.\n",
    "\n",
    "Télécharger l'archive  VKRU18s.tgz depuis le répertoire VKRU18 de PUBLIC_DATASET accessile depuis https://nuage.lip6.fr/s/PQM3RgR4FRnMPQ9  \n",
    "\n",
    "Désarchiver en tapant\n",
    "`tar xvf VKRU18s.tgz`\n",
    "\n",
    "Puis copier les données  `cp -r VKRU18s /tmp/BDLE/dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.30.84.62:4040\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[*], app id = local-1574384157044)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "path: String = C:/Users/yousef/Desktop/Courses/VKRU18s/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path =\"C:/Users/yousef/Desktop/Courses/VKRU18s/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vk: String = C:/Users/yousef/Desktop/Courses/VKRU18s/vk_001.json\r\n",
       "data: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [_id: struct<$oid: string>, code: bigint ... 1 more field]\r\n",
       "total: Long = 30683\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vk = path + \"vk_001.json\"\n",
    "val data = spark.read.format(\"json\").load(vk).dropDuplicates\n",
    "val total = data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage du schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fréquence d'apparition des attributs optionnels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The schema extrait est peu informatif quant à l'optionalité des attributs puisque pour chaque attribut nullable=true.\n",
    "Les instructions suivant comptent la fréqunces d'un certain nombre d'attributs qui sont utiles à l'analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event 30683\n",
      "event.event_id 30683\n",
      "event.event_id.post_id 30683\n",
      "event.event_id.post_owner_id 30683\n",
      "event.event_id.comment_id 16518\n",
      "event.event_id.shared_post_id 638\n",
      "event.author 30683\n",
      "event.attachments 15944\n",
      "event.geo 22\n",
      "event.tags 30683\n",
      "event.creation_time 30683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "attrs: List[String] = List(event, event.event_id, event.event_id.post_id, event.event_id.post_owner_id, event.event_id.comment_id, event.event_id.shared_post_id, event.author, event.attachments, event.geo, event.tags, event.creation_time)\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val attrs = List(\"event\", \n",
    "                 \"event.event_id\", \n",
    "                 \"event.event_id.post_id\", \n",
    "                 \"event.event_id.post_owner_id\", \n",
    "                 \"event.event_id.comment_id\", \n",
    "                 \"event.event_id.shared_post_id\", \n",
    "                 \"event.author\", \n",
    "                 \"event.attachments\", \n",
    "                 \"event.geo\", \n",
    "                 \"event.tags\",\n",
    "                 \"event.creation_time\")\n",
    "\n",
    "attrs.foreach(x=>println(x + \" \"+data.where(x+\" is not null\").count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quels attributs sont optionnels lesquels sont obligatoires?  Extraire les  valeurs distinctes pour se terminant par _id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'apres la documentation officielle https://vk.com/dev/streaming_api_docs_2?f=7.%2BЧтение%2Bпотока il est indiqué que la présence de certains attributs en conditionnée par la valeur que prend un autre attribut.\n",
    "Par exemple, `event.event_id.comment_id` n'est présent que si `event.event_type='comment'`.\n",
    "Idem pour `event.event_id.shared_post_id` qui n'est présent que si `event.event_type='share'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérifier ces hypothèses à l'aide de requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Long = 0\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*vérifier  que `event.event_type='comment'` implique\n",
    "`event.event_id.comment_id` */\n",
    "data.where(\"event.event_type='comment'\").where(\"event.event_id.comment_id is null\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res9: Long = 0\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*vérifier que `event.event_type='share'` implique \n",
    "`event.event_id.shared_post_id` */\n",
    "data.where(\"event.event_type='share'\").where(\"event.event_id.shared_post_id is null\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combien y a t il  de post id différents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.where(\"event.event_id.shared_post_id\").count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res16: Long = 21683\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\"event.event_id.post_id\").distinct().count()//.agg(countDistinct(\"shared_post_id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retourner le nombre de posts par type d'évenement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|event_type|count_post|\n",
      "+----------+----------+\n",
      "|   comment|     14202|\n",
      "|      post|      8137|\n",
      "|     share|       544|\n",
      "+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "postPerType: org.apache.spark.sql.DataFrame = [event_type: string, count_post: bigint]\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val postPerType = data.\n",
    "postPerType.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|event_type|count|\n",
      "+----------+-----+\n",
      "|   comment|14202|\n",
      "|      post| 8137|\n",
      "|     share|  544|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"event.event_type\",\"event.event_id.post_id\").distinct().groupBy(\"event_type\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applatissement des listes de tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la valeur `data` chaque objet est associté à un tableau de tags accessible depuis `event.tags`.\n",
    "L'instruction suivante applatie ce tableau en créant une ligne pour chaque chaine contenue dans tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+---------+\n",
      "|                 _id|code|               event|      tag|\n",
      "+--------------------+----+--------------------+---------+\n",
      "|[5a66276e7f254c35...| 100|[new,, [https://v...| grudinin|\n",
      "|[5a66296f7f254c35...| 100|[new,, [https://v...|    putin|\n",
      "|[5a68d75a713e4d08...| 100|[new,, [https://v...|    putin|\n",
      "|[5a68d75a713e4d08...| 100|[new,, [https://v...|yavlinsky|\n",
      "|[5a68f01c713e4d08...| 100|[new,, [https://v...|  navalny|\n",
      "|[5a68fe3c713e4d08...| 100|[new,, [https://v...|    putin|\n",
      "|[5a690364713e4d08...| 100|[new,, [https://v...|    putin|\n",
      "|[5a69a403713e4d08...| 100|[new, [[,,, [,,, ...|    putin|\n",
      "|[5a69b263713e4d08...| 100|[new, [[,,,,,,,,,...|  navalny|\n",
      "|[5a6a03f7713e4d08...| 100|[new, [[,,,,,,,,,...|    putin|\n",
      "|[5a6af994713e4d08...| 100|[new, [[,,,,,, [c...|    putin|\n",
      "|[5a6b13e4713e4d08...| 100|[new,, [https://v...|    putin|\n",
      "|[5a6b6900713e4d08...| 100|[new, [[,,, [,,, ...|    putin|\n",
      "|[5a6b7918713e4d08...| 100|[new, [[,,,,,,,,,...|  navalny|\n",
      "|[5a6c7a9e713e4d08...| 100|[new, [[,,, [,,, ...| grudinin|\n",
      "|[5a6c844d713e4d08...| 100|[new,, [https://v...|  navalny|\n",
      "|[5a6cb873713e4d08...| 100|[new, [[,,,,,,,,,...| grudinin|\n",
      "|[5a6cdfe0713e4d08...| 100|[new,, [https://v...|  navalny|\n",
      "|[5a6d9add713e4d08...| 100|[new,, [https://v...|    putin|\n",
      "|[5a6efc6f713e4d08...| 100|[new,, [https://v...|    putin|\n",
      "+--------------------+----+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataWithTags: org.apache.spark.sql.DataFrame = [_id: struct<$oid: string>, code: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataWithTags = data.withColumn(\"tag\", explode($\"event.tags\"))\n",
    "dataWithTags.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retourner le nombre de posts par tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "27: error: value postsPerTag is not a member of org.apache.spark.sql.DataFrame\r",
     "output_type": "error",
     "traceback": [
      "<console>:27: error: value postsPerTag is not a member of org.apache.spark.sql.DataFrame\r",
      "possible cause: maybe a semicolon is missing before `value postsPerTag'?\r",
      "       postsPerTag.orderBy($\"count\".desc).show()\r",
      "       ^",
      ""
     ]
    }
   ],
   "source": [
    "val postsPerTag = dataWithTags.\n",
    "postsPerTag.orderBy($\"count\".desc).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|        tag|count|\n",
      "+-----------+-----+\n",
      "|      putin|18869|\n",
      "|   grudinin| 8485|\n",
      "|    navalny| 2768|\n",
      "|    sobchak| 2407|\n",
      "|zhirinovsky| 1290|\n",
      "|      titov|  592|\n",
      "|  yavlinsky|  365|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "postsPerTag: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [tag: string, count: bigint]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val postsPerTag = dataWithTags.groupBy(\"tag\").count().orderBy($\"count\".desc)\n",
    "postsPerTag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.UserDefinedFunction\r\n",
       "tuple: org.apache.spark.sql.expressions.UserDefinedFunction\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.UserDefinedFunction\n",
    "def tuple: UserDefinedFunction =  udf((l: String, r: Integer) => (l,\"vaj\",r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "30: error: type mismatch;\r",
     "output_type": "error",
     "traceback": [
      "<console>:30: error: type mismatch;\r",
      " found   : (org.apache.spark.sql.ColumnName, String, org.apache.spark.sql.ColumnName)\r",
      " required: org.apache.spark.sql.Column\r",
      "       postsPerTag.withColumn(\"dashagh\",($\"tag\",\"hala\",$\"count\")).show()\r",
      "                                        ^",
      ""
     ]
    }
   ],
   "source": [
    "postsPerTag.withColumn(\"dashagh\",($\"tag\",\"hala\",$\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "28: error: too many arguments for method crossJoin: (right: org.apache.spark.sql.Dataset[_])org.apache.spark.sql.DataFrame\r",
     "output_type": "error",
     "traceback": [
      "<console>:28: error: too many arguments for method crossJoin: (right: org.apache.spark.sql.Dataset[_])org.apache.spark.sql.DataFrame\r",
      "       postsPerTag.crossJoin(postsPerTag,\"tag\").show()\r",
      "                            ^",
      ""
     ]
    }
   ],
   "source": [
    "postsPerTag.crossJoin(postsPerTag).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retourner le nombre de posts par auteur id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|        tag|nbAuths|\n",
      "+-----------+-------+\n",
      "|      putin|  15673|\n",
      "|   grudinin|   6207|\n",
      "|    navalny|   2580|\n",
      "|    sobchak|   2288|\n",
      "|zhirinovsky|   1214|\n",
      "|      titov|    572|\n",
      "|  yavlinsky|    347|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "authCountPerTag: org.apache.spark.sql.DataFrame = [tag: string, nbAuths: bigint]\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val authCountPerTag = dataWithTags.\n",
    "authCountPerTag.orderBy($\"nbAuths\".desc).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|        tag|nbAuths|\n",
      "+-----------+-------+\n",
      "|      putin|  18869|\n",
      "|   grudinin|   8485|\n",
      "|    navalny|   2768|\n",
      "|    sobchak|   2407|\n",
      "|zhirinovsky|   1290|\n",
      "|      titov|    592|\n",
      "|  yavlinsky|    365|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "authCountPerTag: org.apache.spark.sql.DataFrame = [tag: string, nbAuths: bigint]\n"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val authCountPerTag =dataWithTags.groupBy(\"tag\").agg(expr(\"count(_id)\").as(\"nbAuths\"))\n",
    "authCountPerTag.orderBy($\"nbAuths\".desc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fact-checking en utilisant Wikipédia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque tag correspond à un candidat de l'élection Russe de 2018 (ex. Putin, Titov, etc).\n",
    "Nous voulons savoir s'il existe une relation entre le nombre de tag par auteur et le nombre de votes de chaque candidat.\n",
    "On récupere depuis Wikipedia le nombre de votes de chaque candidat et on le stocke dans la valeur `votes` décrite ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- party: string (nullable = true)\n",
      " |-- votes: long (nullable = false)\n",
      "\n",
      "+-----------+--------------------+--------+\n",
      "|       name|               party|   votes|\n",
      "+-----------+--------------------+--------+\n",
      "|      putin|         Independent|56430712|\n",
      "|   grudinin|           Communist| 8659206|\n",
      "|zhirinovsky|Liberal Democrati...| 4154985|\n",
      "|    sobchak|    Civic Initiative| 1238031|\n",
      "|  yavlinsky|             Yabloko|  769644|\n",
      "|      titov|     Party of Growth|  556801|\n",
      "+-----------+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\r\n",
       "defined class Vote\r\n",
       "votes: org.apache.spark.sql.Dataset[Vote] = [name: string, party: string ... 1 more field]\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "case class Vote(name: String, party: String, votes: Long)\n",
    "val votes = Seq(Vote(\"putin\", \"Independent\", 56430712), \n",
    "                Vote(\"grudinin\", \"Communist\",8659206), \n",
    "                Vote(\"zhirinovsky\",\"Liberal Democratic Party\",4154985),\n",
    "                Vote(\"sobchak\",\"Civic Initiative\",1238031),\n",
    "                Vote(\"yavlinsky\",\"Yabloko\",769644), \n",
    "                Vote(\"titov\",\"Party of Growth\",556801)).toDS()\n",
    "votes.printSchema\n",
    "votes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créeer une table contenant pour chaque candidate le nombre de votes et le nombre d'auteurs ayant utilisé son nom comme un tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+\n",
      "|       name|   votes|nbAuths|\n",
      "+-----------+--------+-------+\n",
      "|      putin|56430712|  15673|\n",
      "|   grudinin| 8659206|   6207|\n",
      "|    sobchak| 1238031|   2288|\n",
      "|zhirinovsky| 4154985|   1214|\n",
      "|      titov|  556801|    572|\n",
      "|  yavlinsky|  769644|    347|\n",
      "+-----------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "votesCount: org.apache.spark.sql.DataFrame = [name: string, votes: bigint ... 1 more field]\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val votesCount = votes.\n",
    "votesCount.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+\n",
      "|       name|   votes|nbAuths|\n",
      "+-----------+--------+-------+\n",
      "|      putin|56430712|  18869|\n",
      "|   grudinin| 8659206|   8485|\n",
      "|zhirinovsky| 4154985|   1290|\n",
      "|    sobchak| 1238031|   2407|\n",
      "|  yavlinsky|  769644|    365|\n",
      "|      titov|  556801|    592|\n",
      "+-----------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "votesCount: org.apache.spark.sql.DataFrame = [name: string, votes: bigint ... 1 more field]\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val votesCount = votes.\n",
    "    join(authCountPerTag,votes(\"name\") === authCountPerTag(\"tag\")).\n",
    "    orderBy($\"votes\".desc).\n",
    "    select(\"name\",\"votes\",\"nbAuths\")\n",
    "votesCount.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rajouter à la table de votes le rang obtenu à partir du nombre de votes et celui obtenu à partir du nombre d'auteurs. Que remarquez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+----------+-------------+\n",
      "|       name|   votes|nbAuths|votes_rank|nbAuths_ranks|\n",
      "+-----------+--------+-------+----------+-------------+\n",
      "|      putin|56430712|  15673|         1|            1|\n",
      "|   grudinin| 8659206|   6207|         2|            2|\n",
      "|    sobchak| 1238031|   2288|         4|            3|\n",
      "|zhirinovsky| 4154985|   1214|         3|            4|\n",
      "|      titov|  556801|    572|         6|            5|\n",
      "|  yavlinsky|  769644|    347|         5|            6|\n",
      "+-----------+--------+-------+----------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\n",
       "import org.apache.spark.sql.functions._\n",
       "windowSpecVotes: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@16301589\n",
       "windowSpecCount: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@36d3a591\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\r\n",
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+----------+------------+\n",
      "|       name|   votes|nbAuths|votes_rank|nbAuths_rank|\n",
      "+-----------+--------+-------+----------+------------+\n",
      "|      putin|56430712|  18869|         1|           1|\n",
      "|   grudinin| 8659206|   8485|         2|           2|\n",
      "|    sobchak| 1238031|   2407|         4|           3|\n",
      "|zhirinovsky| 4154985|   1290|         3|           4|\n",
      "|      titov|  556801|    592|         6|           5|\n",
      "|  yavlinsky|  769644|    365|         5|           6|\n",
      "+-----------+--------+-------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ranked: org.apache.spark.sql.DataFrame = [name: string, votes: bigint ... 3 more fields]\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var ranked=votesCount.\n",
    "    withColumn(\"votes_rank\",rank().over(Window.orderBy($\"votes\".desc))).\n",
    "    withColumn(\"nbAuths_rank\",rank().over(Window.orderBy($\"nbAuths\".desc)))\n",
    "ranked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons créer une cube pour agéger le posts sur trois dimensions : tag, type d'évenement and mois de création."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rajouter un attribut month contenant le mois extrait pour chaque objet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astuce. importer le package org.apache.spark.sql.types.DateType et utiliser une fonction Spark SQL prédéfinie.\n",
    "Vous remarquerez qu'il n y a que trois mois : 1,2 et 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+---------+-----+\n",
      "|                 _id|code|               event|      tag|month|\n",
      "+--------------------+----+--------------------+---------+-----+\n",
      "|[5a66276e7f254c35...| 100|[new,, [https://v...| grudinin|    1|\n",
      "|[5a66296f7f254c35...| 100|[new,, [https://v...|    putin|    1|\n",
      "|[5a68d75a713e4d08...| 100|[new,, [https://v...|    putin|    1|\n",
      "|[5a68d75a713e4d08...| 100|[new,, [https://v...|yavlinsky|    1|\n",
      "|[5a68f01c713e4d08...| 100|[new,, [https://v...|  navalny|    1|\n",
      "|[5a68fe3c713e4d08...| 100|[new,, [https://v...|    putin|    1|\n",
      "|[5a690364713e4d08...| 100|[new,, [https://v...|    putin|    1|\n",
      "|[5a69a403713e4d08...| 100|[new, [[,,, [,,, ...|    putin|    1|\n",
      "|[5a69b263713e4d08...| 100|[new, [[,,,,,,,,,...|  navalny|    1|\n",
      "|[5a6a03f7713e4d08...| 100|[new, [[,,,,,,,,,...|    putin|    1|\n",
      "|[5a6af994713e4d08...| 100|[new, [[,,,,,, [c...|    putin|    1|\n",
      "|[5a6b13e4713e4d08...| 100|[new,, [https://v...|    putin|    1|\n",
      "|[5a6b6900713e4d08...| 100|[new, [[,,, [,,, ...|    putin|    1|\n",
      "|[5a6b7918713e4d08...| 100|[new, [[,,,,,,,,,...|  navalny|    1|\n",
      "|[5a6c7a9e713e4d08...| 100|[new, [[,,, [,,, ...| grudinin|    1|\n",
      "|[5a6c844d713e4d08...| 100|[new,, [https://v...|  navalny|    1|\n",
      "|[5a6cb873713e4d08...| 100|[new, [[,,,,,,,,,...| grudinin|    1|\n",
      "|[5a6cdfe0713e4d08...| 100|[new,, [https://v...|  navalny|    1|\n",
      "|[5a6d9add713e4d08...| 100|[new,, [https://v...|    putin|    1|\n",
      "|[5a6efc6f713e4d08...| 100|[new,, [https://v...|    putin|    1|\n",
      "+--------------------+----+--------------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.DateType\r\n",
       "dataTagMon: org.apache.spark.sql.DataFrame = [_id: struct<$oid: string>, code: bigint ... 3 more fields]\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.DateType\n",
    "\n",
    "val dataTagMon = dataWithTags.withColumn(\"month\",from_unixtime($\"event.creation_time\",\"M\"))\n",
    "dataTagMon.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que font les instructions suivantes ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+-----+\n",
      "|event_type|     tag|month|count|\n",
      "+----------+--------+-----+-----+\n",
      "|   comment|   putin|    2| 4601|\n",
      "|   comment|   putin|    3| 3997|\n",
      "|      post|   putin|    2| 3654|\n",
      "|      post|   putin|    3| 3561|\n",
      "|   comment|grudinin|    2| 2276|\n",
      "|      post|grudinin|    2| 1836|\n",
      "|   comment|grudinin|    3| 1705|\n",
      "|      post|grudinin|    3| 1688|\n",
      "|   comment|   putin|    1| 1498|\n",
      "|      post|   putin|    1| 1186|\n",
      "|   comment| navalny|    2|  810|\n",
      "|   comment| sobchak|    3|  555|\n",
      "|      post| sobchak|    2|  553|\n",
      "|   comment| navalny|    1|  494|\n",
      "|      post| navalny|    2|  478|\n",
      "|   comment|grudinin|    1|  475|\n",
      "|   comment| sobchak|    2|  445|\n",
      "|      post| sobchak|    3|  438|\n",
      "|   comment| navalny|    3|  423|\n",
      "|      post|grudinin|    1|  388|\n",
      "+----------+--------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cub_ev_tag_mo: org.apache.spark.sql.DataFrame = [event_type: string, tag: string ... 2 more fields]\r\n",
       "cub_ev_tag_mo_notnull: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [event_type: string, tag: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cub_ev_tag_mo =  dataTagMon.rollup(\"event.event_type\", \"tag\", \"month\").count()\n",
    "val cub_ev_tag_mo_notnull = cub_ev_tag_mo.where(\"event_type is not null and tag is not null and month is not null\")\n",
    "cub_ev_tag_mo_notnull.orderBy($\"count\".desc).show()\n",
    "// it makes a calcutes number of --- in for each event_type,tag and month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau croisé "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En utilisant le cube construit précédemment, construire un tableau croisé réduisant le cube aux dimensions mois et type d'évenement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: integer (nullable = true)\n",
      " |-- comment: long (nullable = true)\n",
      " |-- post: long (nullable = true)\n",
      " |-- share: long (nullable = true)\n",
      "\n",
      "+-----+-------+----+-----+\n",
      "|month|comment|post|share|\n",
      "+-----+-------+----+-----+\n",
      "|    1|   2729|2101|  100|\n",
      "|    3|   7130|6442|  208|\n",
      "|    2|   8594|7057|  415|\n",
      "+-----+-------+----+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "monthEvent: org.apache.spark.sql.DataFrame = [month: int, comment: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val monthEvent = cub_ev_tag_mo_notnull.groupBy(\"event_type\",\"month\")\n",
    "monthEvent.printSchema\n",
    "monthEvent.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----+-----+\n",
      "|month|comment|post|share|\n",
      "+-----+-------+----+-----+\n",
      "|    3|   7130|6442|  208|\n",
      "|    1|   2729|2101|  100|\n",
      "|    2|   8594|7057|  415|\n",
      "+-----+-------+----+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "monthEvent: org.apache.spark.sql.DataFrame = [month: string, comment: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val monthEvent = cub_ev_tag_mo_notnull.groupBy(\"month\").pivot(\"event_type\").sum(\"count\")\n",
    "monthEvent.show()\n",
    "//groupBy(\"id\").pivot(\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "26: error: not found: value monthEvent\r",
     "output_type": "error",
     "traceback": [
      "<console>:26: error: not found: value monthEvent\r",
      "       monthEvent.crossJoin(monthEvent)\r",
      "       ^",
      "<console>:26: error: not found: value monthEvent\r",
      "       monthEvent.crossJoin(monthEvent)\r",
      "                            ^",
      ""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Matrice de co-occurrence des tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une table indiquant pour chaque paire de tag le nombre d'auteur qui les utilisent en même temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+\n",
      "|        tag|   otherTag|count|\n",
      "+-----------+-----------+-----+\n",
      "|      putin|   grudinin| 7267|\n",
      "|   grudinin|      putin| 7267|\n",
      "|      putin|    navalny| 1806|\n",
      "|    navalny|      putin| 1806|\n",
      "|    sobchak|      putin| 1299|\n",
      "|      putin|    sobchak| 1299|\n",
      "|    navalny|   grudinin| 1113|\n",
      "|   grudinin|    navalny| 1113|\n",
      "|      putin|zhirinovsky|  901|\n",
      "|zhirinovsky|      putin|  901|\n",
      "|   grudinin|    sobchak|  722|\n",
      "|    sobchak|   grudinin|  722|\n",
      "|zhirinovsky|   grudinin|  714|\n",
      "|   grudinin|zhirinovsky|  714|\n",
      "|zhirinovsky|    sobchak|  439|\n",
      "|    sobchak|zhirinovsky|  439|\n",
      "|      putin|  yavlinsky|  355|\n",
      "|  yavlinsky|      putin|  355|\n",
      "|    sobchak|    navalny|  300|\n",
      "|    navalny|    sobchak|  300|\n",
      "+-----------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "authTag: org.apache.spark.sql.DataFrame = [authorID: bigint, tag: string]\n",
       "tagCoOcc: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [authorID: bigint, otherTag: string ... 1 more field]\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val authTag = dataWithTags.\n",
    "val tagCoOcc = authTag.\n",
    "tagCoOcc.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----+\n",
      "|        tag| otherTag|count|\n",
      "+-----------+---------+-----+\n",
      "|      putin| grudinin| 1479|\n",
      "|  yavlinsky|  sobchak|  164|\n",
      "|    sobchak| grudinin|  332|\n",
      "|zhirinovsky|yavlinsky|  116|\n",
      "|    sobchak|  navalny|  187|\n",
      "|  yavlinsky| grudinin|  138|\n",
      "|  yavlinsky|    putin|  142|\n",
      "|zhirinovsky|    putin|  332|\n",
      "|  yavlinsky|    titov|   78|\n",
      "|      titov|  navalny|    8|\n",
      "|    sobchak|    putin|  507|\n",
      "|zhirinovsky|  navalny|   48|\n",
      "|      putin|  navalny|  480|\n",
      "|zhirinovsky|    titov|   79|\n",
      "|      titov|  sobchak|   90|\n",
      "|zhirinovsky| grudinin|  289|\n",
      "|  yavlinsky|  navalny|   35|\n",
      "|      titov|    putin|  101|\n",
      "|    navalny| grudinin|  264|\n",
      "|zhirinovsky|  sobchak|  346|\n",
      "|      titov| grudinin|   86|\n",
      "+-----------+---------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataWithTags_a: org.apache.spark.sql.DataFrame = [_id: struct<$oid: string>, code: bigint ... 2 more fields]\r\n",
       "TupletagsPerAuthor_a: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [_id: struct<$oid: string>, code: bigint ... 6 more fields]\r\n",
       "tagCoOcc: org.apache.spark.sql.DataFrame = [tag: string, otherTag: string ... 1 more field]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataWithTags_a = dataWithTags.withColumnRenamed(\"event\", \"event1\").withColumnRenamed(\"tag\", \"otherTag\")\n",
    "val TupletagsPerAuthor_a = dataWithTags.join(dataWithTags_a).where(\"(event.event_id = event1.event_id) and (event.author.id = event1.author.id) and (tag > otherTag)\")\n",
    "val tagCoOcc = TupletagsPerAuthor_a.groupBy(\"tag\", \"otherTag\").agg(size(collect_set(\"event.author.id\")) as \"count\")\n",
    "tagCoOcc.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construire une matrice de co-occurrence des tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+-----+-------+-----+---------+-----------+\n",
      "|        tag|grudinin|navalny|putin|sobchak|titov|yavlinsky|zhirinovsky|\n",
      "+-----------+--------+-------+-----+-------+-----+---------+-----------+\n",
      "|   grudinin|    null|   1113| 7267|    722|  140|      210|        714|\n",
      "|    navalny|    1113|   null| 1806|    300|   21|       60|         90|\n",
      "|      putin|    7267|   1806| null|   1299|  246|      355|        901|\n",
      "|    sobchak|     722|    300| 1299|   null|  111|      199|        439|\n",
      "|      titov|     140|     21|  246|    111| null|       94|         90|\n",
      "|  yavlinsky|     210|     60|  355|    199|   94|     null|        145|\n",
      "|zhirinovsky|     714|     90|  901|    439|   90|      145|       null|\n",
      "+-----------+--------+-------+-----+-------+-----+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tagMat: org.apache.spark.sql.DataFrame = [tag: string, grudinin: bigint ... 6 more fields]\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tagMat = tagCoOcc.groupBy(\"tag\").pivot(\"otherTag\").agg(sum(\"count\") as \"count\")\n",
    "tagMat.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
